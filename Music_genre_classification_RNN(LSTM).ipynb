{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_genre_classification_RNN(LSTM).ipynb",
      "provenance": [],
      "mount_file_id": "14KZ-T1sDlKBBngasgTt_svpG9UUheiv5",
      "authorship_tag": "ABX9TyPM+Y1Vikzl+U74C7Tw/YQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyunLee103/Audio_data_preprocessing/blob/master/Music_genre_classification_RNN(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcUloWOhIwpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T85GcmgaN4jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only in colab\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnhk2iFlJh-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/Sound AI/data_10.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpGPNQl3JybR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "def load_data(data_path):\n",
        "  with open(data_path, \"r\") as fp :\n",
        "    data = json.load(fp)\n",
        "\n",
        "  X = np.array(data['mfcc'])\n",
        "  y = np.array(data['labels'])\n",
        "\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A0EwaQCKsKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history 함수 \n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "  fig, axs = plt.subplot(2)\n",
        "\n",
        "  axs[0].plot(history.history['accuaracy'], label = 'train acc')\n",
        "  axs[0].plot(history.history['val_accuracy'], label = 'val acc')\n",
        "  \n",
        "  axs[1].plot(history.history['loss'],label='train loss')\n",
        "  axs[1].plot(history.history['val_loss'], label='val loss')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8jLcpXYMiiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 \n",
        "\n",
        "def prepare_data(test_size, val_size):\n",
        "  X,y = load_data(DATA_PATH)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_size)\n",
        "  X_train, X_val , y_train, y_val = train_test_split(X_train,y_train, test_size=val_size)\n",
        "\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nY70jNFNWz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 \n",
        "\n",
        "def modeling(input):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.LSTM(128,input_shape = input, return_sequences=True)) # return_sequences = True 는 아웃풋을 sequences로 출력하겠다는 뜻\n",
        "                                                                                 # 이걸 해야 이 sequence 아웃풋을 다음 LSTM layer에 넣을 수 있다.\n",
        "  model.add(tf.keras.layers.LSTM(128, return_sequences=True))                     # RNN 계열은 모델안에 activation 함수가 들어가 있다. 따로 줄 필요 없음\n",
        "  model.add(tf.keras.layers.LSTM(128, return_sequences=False))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "  return model \n",
        "\n",
        "# Q : RNN 계열에서 배치놈 안하나?\n",
        "# A : 가능은 한데 CNN, DNN 계열에 비해 의미가 없다. 왜냐면 CNN에서는 BN이 채널 차원으로 적용된다. RNN에서도 동일하게 수직방향으로 BN이 작용해\n",
        "# BN이 미니배치와 각 step에 대해 적용된다. 따라서 RNN에서 중요하게 여기는 시계열성을 반영하지 못하므로 그 효과가 미비하다.\n",
        "# 그래서 layer normalization이라는 새로운 기법이 제시되었다.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anZ1aou1VNr9",
        "colab_type": "code",
        "outputId": "99cd383f-9e72-4c4f-d2ee-4bd15f032e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # get train, validation, test splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_data(0.25, 0.2)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2]) # 130, 13\n",
        "    model = modeling(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n",
        "\n",
        "    # plot accuracy/error for training and validation\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 259, 128)          72704     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 259, 128)          131584    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 353,674\n",
            "Trainable params: 353,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "94/94 [==============================] - 6s 67ms/step - loss: 2.1710 - accuracy: 0.2392 - val_loss: 1.9708 - val_accuracy: 0.3680\n",
            "Epoch 2/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.7977 - accuracy: 0.3719 - val_loss: 1.6140 - val_accuracy: 0.4293\n",
            "Epoch 3/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.5757 - accuracy: 0.4273 - val_loss: 1.4694 - val_accuracy: 0.4933\n",
            "Epoch 4/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.4697 - accuracy: 0.4696 - val_loss: 1.4199 - val_accuracy: 0.5267\n",
            "Epoch 5/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.3599 - accuracy: 0.5213 - val_loss: 1.3353 - val_accuracy: 0.5520\n",
            "Epoch 6/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.2518 - accuracy: 0.5620 - val_loss: 1.2924 - val_accuracy: 0.5387\n",
            "Epoch 7/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.1809 - accuracy: 0.5914 - val_loss: 1.2367 - val_accuracy: 0.5640\n",
            "Epoch 8/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.1165 - accuracy: 0.6124 - val_loss: 1.2389 - val_accuracy: 0.5760\n",
            "Epoch 9/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 1.0401 - accuracy: 0.6401 - val_loss: 1.1971 - val_accuracy: 0.5853\n",
            "Epoch 10/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.9659 - accuracy: 0.6805 - val_loss: 1.1669 - val_accuracy: 0.6080\n",
            "Epoch 11/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.9105 - accuracy: 0.6988 - val_loss: 1.1390 - val_accuracy: 0.6107\n",
            "Epoch 12/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.8781 - accuracy: 0.7105 - val_loss: 1.1667 - val_accuracy: 0.6160\n",
            "Epoch 13/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.8306 - accuracy: 0.7348 - val_loss: 1.1650 - val_accuracy: 0.6093\n",
            "Epoch 14/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.7686 - accuracy: 0.7418 - val_loss: 1.1383 - val_accuracy: 0.6280\n",
            "Epoch 15/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.7299 - accuracy: 0.7745 - val_loss: 1.1318 - val_accuracy: 0.6547\n",
            "Epoch 16/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.7158 - accuracy: 0.7759 - val_loss: 1.1192 - val_accuracy: 0.6600\n",
            "Epoch 17/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.6608 - accuracy: 0.7949 - val_loss: 1.1204 - val_accuracy: 0.6560\n",
            "Epoch 18/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.8576 - accuracy: 0.7218 - val_loss: 1.2346 - val_accuracy: 0.5960\n",
            "Epoch 19/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.7207 - accuracy: 0.7678 - val_loss: 1.1879 - val_accuracy: 0.6267\n",
            "Epoch 20/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.6521 - accuracy: 0.7915 - val_loss: 1.1492 - val_accuracy: 0.6520\n",
            "Epoch 21/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.6316 - accuracy: 0.8015 - val_loss: 1.1746 - val_accuracy: 0.6347\n",
            "Epoch 22/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.5585 - accuracy: 0.8309 - val_loss: 1.1602 - val_accuracy: 0.6533\n",
            "Epoch 23/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.4997 - accuracy: 0.8512 - val_loss: 1.1787 - val_accuracy: 0.6587\n",
            "Epoch 24/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.4746 - accuracy: 0.8516 - val_loss: 1.1698 - val_accuracy: 0.6707\n",
            "Epoch 25/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.4862 - accuracy: 0.8549 - val_loss: 1.1522 - val_accuracy: 0.6733\n",
            "Epoch 26/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.6028 - accuracy: 0.8099 - val_loss: 1.1222 - val_accuracy: 0.6800\n",
            "Epoch 27/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.4650 - accuracy: 0.8522 - val_loss: 1.1452 - val_accuracy: 0.6747\n",
            "Epoch 28/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.4127 - accuracy: 0.8736 - val_loss: 1.2245 - val_accuracy: 0.6733\n",
            "Epoch 29/30\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.3534 - accuracy: 0.8929 - val_loss: 1.1602 - val_accuracy: 0.6893\n",
            "Epoch 30/30\n",
            "94/94 [==============================] - 5s 57ms/step - loss: 0.3920 - accuracy: 0.8866 - val_loss: 1.2324 - val_accuracy: 0.6680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1ae0534f88ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# plot accuracy/error for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# evaluate model on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-eae497ed854c>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuaracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m                 raise ValueError(\"Integer subplot specification must be a \"\n\u001b[0;32m-> 1381\u001b[0;31m                                  \"three-digit number, not {}\".format(args[0]))\n\u001b[0m\u001b[1;32m   1382\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Integer subplot specification must be a three-digit number, not 2"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19X-V8-kVi08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}